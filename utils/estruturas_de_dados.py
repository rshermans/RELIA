import streamlit as st
import openai
import tiktoken # type: ignore
from utils.api import get_openai_response
import re
import sqlite3
from database import carregar_dados_banco, obter_nome_acao_por_id
import random
import streamlit.components.v1 as components


#  Estrutura de dados para representar os n√≠veis de Bloom e as a√ß√µes

#------------------ Revis√£o de incosistencias e adapta√ß√£o para tabela acoes-----------------------------

# Estabelecer a conex√£o com o banco de dados
conn = sqlite3.connect('relia.db') 

@st.cache_data
def get_dados_banco():
    return carregar_dados_banco(conn)


def encontrar_acao_checkpoint(nivel_bloom, pontuacao_total, acoes_niveis):
    # Filtrar a√ß√µes pelo n√≠vel de Bloom
    acoes_do_nivel = [
        acao_id for acao_id, dados in acoes_niveis.items() 
        if dados.get('nivel_bloom') == nivel_bloom
    ]
    
    if not acoes_do_nivel:
        return None
    
    # Debug: Mostrar a√ß√µes dispon√≠veis para o n√≠vel atual
    #st.write(f"A√ß√µes dispon√≠veis para o n√≠vel '{nivel_bloom}': {acoes_do_nivel}")
    
    
    # Randomizar uma a√ß√£o do n√≠vel
    acao_id = random.choice(acoes_do_nivel)
    pontos_acao = acoes_niveis[acao_id].get('pontos', 1)  # Exemplo de pontos
    tipo_resposta = acoes_niveis[acao_id].get('tipo_resposta', 'texto')  # Exemplo de tipo
    nomes_acao = acoes_niveis[acao_id].get('nomes_acao', 'A√ß√£o Desconhecida')
    
    return acao_id, pontos_acao, tipo_resposta, nomes_acao


# Fun√ß√£o para limitar a quantidade de tokens
def limitar_tokens(texto, max_tokens=1000):
    enc = tiktoken.encoding_for_model("gpt-4o-mini")
    tokens = enc.encode(texto)

    if len(tokens) > max_tokens:
        tokens = tokens[:max_tokens]
    
    return enc.decode(tokens)

# Fun√ß√£o para resumir o hist√≥rico de mensagens
def resumir_historico_mensagens(mensagens, max_tokens=600):
    texto_completo = " ".join([msg['content'] for msg in mensagens])
    texto_resumido = limitar_tokens(texto_completo, max_tokens)
    
    resumo_final = [{"role": "system", "content": "Resumo do hist√≥rico anterior:"},
                    {"role": "user", "content": texto_resumido}]
    
    return resumo_final


def gerar_resposta_chatgpt(prompt, historico_mensagens=None, max_tokens=1500):
    """
    Gera uma resposta utilizando o ChatGPT, com a adapta√ß√£o para limitar tokens e resumir o hist√≥rico de mensagens.
    """
    try:
        # Verifica se h√° hist√≥rico de mensagens a ser resumido
        if historico_mensagens:
            # Resumir o hist√≥rico de mensagens se existir
            mensagens_resumidas = resumir_historico_mensagens(historico_mensagens, max_tokens)
        else:
            mensagens_resumidas = []

        # Adiciona o prompt atual √† lista de mensagens
        mensagens_resumidas.append({"role": "user", "content": prompt})

        # Chamada para a API da LLM
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=mensagens_resumidas,
            max_tokens=3000,  # Ajuste do limite de tokens para a resposta
            temperature=0.7
        )

        # Extrair e retornar a resposta
        resposta = response.choices[0]['message']['content'].strip()
        return resposta
    
    except Exception as e:
        print(f"Erro ao se comunicar com a LLM: {e}")
        return None
    

def obter_resposta_texto(acao_id):
    key = f"resposta_texto_{acao_id}"
    valor_inicial = st.session_state.get(key, "")
    cole, colR,cole2 = st.columns([1, 4, 1])
    with colR:  resposta = st.text_area(f"Resposta para a a√ß√£o {obter_nome_acao_por_id(acao_id)}:", value=valor_inicial, height=100, key=key)
        # Atualizar o session_state ap√≥s a resposta ser modificada
    if resposta:
        st.session_state[key] = resposta
    # Injetar CSS para destacar o campo de texto
    st.markdown(f"""
        <style>
            /* Estilizando o textarea do Streamlit */
            textarea[data-testid="stTextArea"][aria-describedby*="{key}"] {{
                background-color: #f0f9ff;  /* Cor de fundo azul claro suave */
                box-shadow: 0 0 10px rgba(0, 123, 255, 0.3);  /* Sombra azul suave ao redor do campo */
                border-radius: 10px;  /* Bordas arredondadas para um visual amig√°vel */
                transition: background-color 0.3s ease-in-out, box-shadow 0.3s ease-in-out;  /* Suaviza√ß√£o das mudan√ßas */
            }}

            /* Destaque ao focar no campo de texto */
            textarea[data-testid="stTextArea"][aria-describedby*="{key}"]:focus {{
                background-color: #e6f7ff;  /* Cor de fundo mais intensa quando em foco */
                box-shadow: 0 0 15px rgba(0, 123, 255, 0.5);  /* Sombra mais intensa para indicar foco */
                outline: none;  /* Remover outline padr√£o do navegador */
            }}
        </style>
    """, unsafe_allow_html=True)

    print("Resposta na fun√ß√£o resposta texto: ",resposta)
    return resposta


def obter_resposta_quizz(acao_id):
    options = ["Op√ß√£o 1", "Op√ß√£o 2", "Op√ß√£o 3", "Op√ß√£o 4"]
    key = f"resposta_quizz_{acao_id}"
    valor_inicial = st.session_state.get(key, options[0])
    resposta = st.radio(f"Selecione a resposta correta para a a√ß√£o {acao_id}:", options, index=options.index(valor_inicial), key=key)
    return resposta


def obter_resposta_input(acao_id):
    key = f"resposta_input_{acao_id}"
    valor_inicial = st.session_state.get(key, "")
    resposta = st.text_input(f"Resposta para a a√ß√£o {acao_id}:", value=valor_inicial, key=key)
    return resposta


def obter_resposta_checkbox(acao_id, opcoes=None):
    if opcoes is None:
        opcoes = ["Item 1", "Item 2", "Item 3"]
    key = f"resposta_checkbox_{acao_id}"
    valor_inicial = st.session_state.get(key, [])
    resposta = st.multiselect(f"Selecione as op√ß√µes para a a√ß√£o {acao_id}:", opcoes, default=valor_inicial, key=key)
    return resposta


def obter_resposta_slider(acao_id, min_val=0, max_val=1000):
    key = f"resposta_slider_{acao_id}"
    valor_inicial = st.session_state.get(key, min_val)
    resposta = st.slider(f"Resposta para a a√ß√£o {acao_id}:", min_value=min_val, max_value=max_val, value=valor_inicial, key=key)
    return resposta


def exibir_campo_resposta_OLD(tipo_resposta, acao_id):
    """
    Exibe o campo de resposta apropriado com base no tipo de resposta.

    Par√¢metros:
    - tipo_resposta (str): O tipo de resposta esperado (e.g., 'texto', 'quizz', 'input', 'checkbox', 'slider').
    - acao_id (int): O ID da a√ß√£o atual.

    Retorna:
    - resposta_usuario (str): A resposta fornecida pelo usu√°rio.
    """
    tipo_resposta = tipo_resposta.lower()
    
    mapeamento_widgets = {
        'texto': obter_resposta_texto,
        'textarea': obter_resposta_texto,
        'quizz': obter_resposta_quizz,
        'input': obter_resposta_input,
        'checkbox': obter_resposta_checkbox,
        'slider': obter_resposta_slider
    }
    
    if tipo_resposta in mapeamento_widgets:
        resposta = mapeamento_widgets[tipo_resposta](acao_id)
        print("Resposta na fun√ß√£o exibir campo: ",resposta)
        st.session_state['resposta'] = resposta
    else:
        st.error(f"Tipo de resposta '{tipo_resposta}' desconhecido.")
        resposta = None  
    return resposta



def exibir_campo_resposta(tipo_resposta, acao_id):
    """
    Exibe o campo de resposta baseado no tipo de resposta.
    Atualiza o st.session_state com a resposta do usu√°rio.
    """
    resposta_key = f'resposta_{acao_id}'
    
    if tipo_resposta == 'texto' or 'textarea':
        resposta = st.text_area("Sua Resposta:",value="", key=resposta_key)
        st.session_state['resposta'] = resposta
        #print("Sesion State na fun√ß√£o exibir campo: ",{st.session_state['resposta']})
        print("Resposta na fun√ß√£o exibir campo: ",resposta)
        return resposta
    elif tipo_resposta == 'multiple_choice':
        # Exemplo de campo de m√∫ltipla escolha
        opcoes = ['Op√ß√£o 1', 'Op√ß√£o 2', 'Op√ß√£o 3']
        resposta = st.radio("Escolha uma op√ß√£o:", opcoes, key=resposta_key)
        return resposta
    # Adicione outros tipos de resposta conforme necess√°rio
    else:
        st.error("Tipo de resposta desconhecido.")
        return ""



# Fun√ß√µes revisadas pelo GPT o1-Preview


def gerar_pergunta_com_llm(acao_data, contexto):
    """
    Gera uma pergunta personalizada usando a LLM, com base em uma a√ß√£o e no contexto da obra.
    """
    try:
        prompt = (
            f"Crie uma pergunta de {contexto['nivel_bloom']} sobre a obra '{contexto['obra']}' de {contexto['autor']} "
            f"focalizada na a√ß√£o de '{acao_data['nomes_acao']}'.  O leitor √© {contexto['perfil_usuario']}. "
            f"A pergunta deve ser concisa e clara e objetiva para o contexto apresentado e n√£o conter links ou outros elementos formatados.  "
            f"Exemplo de pergunta: '{acao_data['template_pergunta'].format(obra=contexto['obra'])}'"
        )

        pergunta = get_openai_response(prompt)  # Retorna a pergunta obtida da LLM.

        if pergunta is None or not pergunta:  # Lida com resposta nula ou vazia da LLM.
           return st.error("Erro ao gerar pergunta. Tente novamente.")
        
        return pergunta  
    except Exception as e:
        return st.error(f"Erro ao gerar pergunta: {e}")



def avaliar_resposta_com_llm(pergunta, resposta_usuario, contexto):
    """
    Avalia a resposta do usu√°rio usando a LLM e retorna o feedback e a pontua√ß√£o.
    
    Par√¢metros:
    - pergunta (str): A pergunta feita ao usu√°rio.
    - resposta_usuario (str): A resposta fornecida pelo usu√°rio.
    - contexto (dict): Dicion√°rio contendo informa√ß√µes contextuais como obra, autor, n√≠vel de Bloom, etc.
    
    Retorna:
    - feedback_final (str): Feedback detalhado sobre a resposta do usu√°rio.
    - pontuacao (int): Pontua√ß√£o obtida pelo usu√°rio.
    """
    prompt = gerar_prompt_avaliacao(pergunta, resposta_usuario, contexto)
    
    try:
        # Obter a resposta do LLM
        resposta_avaliacao = get_openai_response(prompt)

        if not resposta_avaliacao:
            st.error("Erro ao avaliar a resposta com a LLM. A resposta n√£o foi recuperada.")
            return "Erro na avalia√ß√£o da resposta.", 0

        # Processar a resposta da LLM
        feedback_final, pontuacao = processar_resposta_llm(resposta_avaliacao)

        # Atualizar a pontua√ß√£o total do usu√°rio
        #st.session_state['pontuacao_total'] += pontuacao

        return feedback_final, pontuacao

    except Exception as e:
        st.error(f"Erro inesperado ao avaliar a resposta da LLM: {e}")
        return "Erro na avalia√ß√£o da resposta.", 0


def obter_acao_por_nivel_e_pontuacao(nivel_bloom, pontuacao):
    # Conectar ao banco de dados
    conn = sqlite3.connect('relia.db')
    cursor = conn.cursor()

    # Consultar a a√ß√£o pelo n√≠vel de Bloom e pela pontua√ß√£o
    cursor.execute("SELECT * FROM acoes WHERE nivel_bloom = ? AND pontos = ?", (nivel_bloom, pontuacao))
    acao = cursor.fetchone()

    # Fechar a conex√£o com o banco de dados
    conn.close()

    # Se a a√ß√£o for encontrada, retornar um dicion√°rio com os dados
    if acao:
        return {
            "id": acao[0],
            "nome": acao[1],
            "nivel_bloom": acao[2],
            "pontos": acao[3],
            "tipo_resposta": acao[4],
            "template_pergunta": acao[5],
            "respostas_esperadas": acao[6]
        }
    else:
        return None

# Dicion√°rio com a estrutura da rubrica de avalia√ß√£o
# Perguntas para cada n√≠vel


def obter_nivel_atual_usuario():
    """
    Obt√©m o n√≠vel atual do usu√°rio com base na pontua√ß√£o total.
    """
    pontuacao_total = st.session_state.get('pontuacao_total', 0)
    nivel_bloom = determinar_nivel_bloom(pontuacao_total)
    return nivel_bloom, pontuacao_total


def determinar_nivel_bloom(pontuacao):
    """
    Determina o n√≠vel de profici√™ncia com base na pontua√ß√£o.
    """
    if pontuacao <= 15:
        return "Lembrar"
    elif pontuacao <= 45:
        return "Compreender"
    elif pontuacao <= 91:
        return "Aplicar"
    elif pontuacao <= 153:
        return "Analisar"
    elif pontuacao <= 190:
        return "Avaliar"
    else:
        return "Criar"


def gerar_prompt_avaliacao(pergunta, resposta_usuario, contexto):
    """
    Gera o prompt para avalia√ß√£o da resposta do Leitor pela LLM.
    
    Par√¢metros:
    - pergunta (str): A pergunta feita ao Leitor.
    - resposta_usuario (str): A resposta fornecida pelo Leitor.
    - contexto (dict): Dicion√°rio contendo informa√ß√µes contextuais como obra, autor, n√≠vel de Bloom, etc.
    
    Retorna:
    - prompt (str): O prompt formatado para enviar √† LLM.
    """
    prompt = f"""
    Avalie a resposta a esta pergunta, considerando a obra '{contexto['obra']}', o n√≠vel da Taxonomia de Bloom {contexto['nivel_bloom']} e o contexto fornecido.
    
    **Pergunta:** {pergunta}

    **Resposta do Usu√°rio:** {resposta_usuario}

    **Avalia√ß√£o (Se v√°lida ou n√£o a pontua√ß√£o e Feedback):**

    Por favor, forne√ßa uma avalia√ß√£o construtiva seguindo este formato:

    Pontua√ß√£o: [0-10]
    Feedback: [feedback detalhado sobre a resposta do Leitor, explicando as raz√µes para a pontua√ß√£o]

    Exemplo de resposta: 
    Pontua√ß√£o: 8
    Feedback: üí´ Pontos Fortes:
    - Excelente identifica√ß√£o do conflito interno do protagonista
    - An√°lise perspicaz da simbologia presente no cap√≠tulo 3
    
    üìà Oportunidades de Desenvolvimento:
    - Explore mais a fundo a rela√ß√£o entre o contexto hist√≥rico e as escolhas do autor
    - Considere como os elementos narrativos contribuem para o tema central

    üîç Feedback Personalizado:
    Sua interpreta√ß√£o demonstra sensibilidade e compreens√£o profunda da obra. Voc√™ captou muito bem as nuances do personagem principal e trouxe observa√ß√µes valiosas sobre a narrativa. Para enriquecer ainda mais sua an√°lise, sugiro explorar como o contexto social da √©poca influenciou a escrita do autor.

    üìñ Sugest√£o de Leitura Complementar:
    Recomendo a leitura de "T√≠tulo Relacionado" de Autor Complementar, que aborda temas similares e pode oferecer novas perspectivas para sua an√°lise.

    - Se tiver d√∫vida que a obra exista em portug√™s pode mostrar em ingl√™s. N√£o alucine e nem crie sugest√µes que n√£o existam. Se n√£o tiver certeza do que sugerir, sugira trechos da obra, ou temas. 
        Avise se houver imprecis√µes ou duvidas nas sugest√µes. Seja cauteloso e respons√°vel pelas informa√ß√µes prestadas sobre o feedback e sobre a obra. Mas seja sempre inovador e disrruptivo. 
    """
    return prompt


def processar_resposta_llm(resposta_avaliacao):
    """
    Processa a resposta da LLM para extrair a pontua√ß√£o e o feedback.
    
    Par√¢metros:
    - resposta_avaliacao (str): A resposta recebida da LLM.
    
    Retorna:
    - feedback_final (str): Feedback detalhado sobre a resposta do usu√°rio.
    - pontuacao (int): Pontua√ß√£o obtida pelo usu√°rio.
    """
    pontuacao = extrair_pontuacao(resposta_avaliacao)
    feedback_final = extrair_feedback(resposta_avaliacao)
    return feedback_final, pontuacao


def validar_pontuacao(pontuacao_llm, pontos_acao):
    """
    Valida a pontua√ß√£o da a√ß√£o com base na pontua√ß√£o da LLM.
    
    Args:
        pontuacao_llm (int): Pontua√ß√£o recebida da LLM (0 a 10).
        pontos_acao (int): Pontua√ß√£o atribu√≠da √† a√ß√£o.
    
    Returns:
        int: Pontua√ß√£o validada (pontos_acao ou 0).
    """
    if pontuacao_llm < 0 or pontuacao_llm > 10:
        st.error("Pontua√ß√£o da LLM inv√°lida. Deve estar entre 0 e 10.")
        return 0
    if pontuacao_llm >= 5:
        return pontos_acao
    else:
        return 0
    
    
def extrair_pontuacao(resposta_avaliacao):
    # Fun√ß√£o para extrair a pontua√ß√£o da resposta da LLM
    pontuacao_match = re.search(r"Pontua√ß√£o:\s*(\d+)", resposta_avaliacao, re.IGNORECASE)
    if pontuacao_match:
        try:
            pontuacao = int(pontuacao_match.group(1))
            if pontuacao < 0 or pontuacao > 10:
                st.error(f"Pontua√ß√£o inv√°lida recebida: {pontuacao}. Deve estar entre 0 e 10.")
                return 0
            return pontuacao
        except ValueError:
            st.error(f"Erro ao converter pontua√ß√£o para inteiro: {pontuacao_match.group(1)}")
            return 0
    else:
        st.error("Pontua√ß√£o n√£o encontrada na resposta da LLM.")
        return 0

def extrair_feedback(resposta_avaliacao):
    # Fun√ß√£o para extrair o feedback da resposta da LLM
    feedback_match = re.search(r"Feedback:\s*(.*)", resposta_avaliacao, re.IGNORECASE | re.DOTALL)
    return feedback_match.group(1).strip() if feedback_match else "Feedback n√£o fornecido."
    
        
